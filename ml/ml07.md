# 机器学习 [07] ⚡️的力量

*模型的评估指标* From <机器学习 40 讲>

模型评估中使用的是测试数据集，通过衡量模型在从未出现过的数据上的性能来估计模型的泛化特点。

**分类正确的样本占样本总数的比例是精度，分类错误的样本占样本总数的比例是错误率，两者之和等于 1。**

为了更清楚地体现出不同的错误类型的影响，机器学习采用了混淆矩阵，也叫列联表来对不同的划分结果加以划分。

在混淆矩阵中，所有测试样例被分为真正例（true positive，TP）、假正例（false position，FP）、假反例（false negative，FN）和真反例（true negative，TN）四大类。

这样的分类能够对机器学习模型的性能做出更加精细的刻画，**查准率（precision）**和**查全率（recall）**就是两个具体的刻画指标。

**查准率 P 也叫正例预测值，表示的是真正例占所有预测结果为正例的样例的比值，也就是模型预测结果的准确程度**，写成数据表达式是：

`P = PPV = TP / (TP + FP)`

**查全率 R 也叫真正例率，表示的是真正例占所有真实情况为正例的样例的比值，也就是模型对真实正例的判断能力**，写成数学表达式是：

`R = TPR = TP / (TP + FN)` 

一般情况下，查准率和查全率是鱼与熊掌不可兼得的一对指标。

将查准率和查全率画在同一个平面直角坐标系内，得到的就是 P-R 曲线，它表示了模型可以同时达到的查准率和查全率。

除了 P-R 曲线外，另一个对机器学习模型性能进行可视化的方式是**受试者工作特性曲线**，简称**ROC 曲线**。

**ROC曲线描述的是真正例率和假正例率之间的关系，也就是收益（真正例）与代价（假正例）之间的关系**。所谓的假正例率（FPR）等于假正例和所有真实反例之间的比值，其数学表达式为：

`FPR = FP / (FP + TN)`

ROC 空间将 FPR 定义为 X 轴，TPR 定义为 Y 轴。给定一个二元分类模型和它的阈值，就是能计算出模型的 FPR 和 TPR ，并映射成由 (0,0)、(0,1)、(1,0)、(1,1)四个点围成的正方形里。在这个正方形里，从 (0,0) 到 （1，1）的对角线代表了一条分界线，叫做**无识别率线**，它将 ROC 空间划分成左上/右下两个区域。

无识别率线描述的是随机猜测的模型，以 0.5 的概率将新来的实例判定为正例，这种模型的 TPR 和 FPR 是处处相等的。在无识别率左上方，所有点的 TPR 都大于 FPR，意味着分类结果优于二选一的随机猜测；而在无识别率右下方，所有点的 TPR 都小于 FPR，意味着分类结果劣于随机猜测。**完美的模型体现在 ROC 空间上的 (0, 1) 点：FPR = 0 意味着没有假正例，没有负例被掺入；TPR = 1意味着没有假负例，没有正例被遗漏**。也就是说，不管分类器输出结果是正例还是反例，都是 100% 完全正确。

ROC 曲线可以用来衡量习得模型的性能。模型的 ROC 曲线越靠近左上方，其性能就越好。和 P-R 曲线一样，如果一个模型的 ROC 曲线完全包住另一个模型的曲线，那么前者的性能就优于后者。

**ROC 曲线下面积简称 AUC**。AUC 等于 0.5 的模型完全没有预测价值。一般来说，通过调整模型的阈值，可以让模型的最优 AUC 大于 0.5，达到比随机猜测更好的判别效果。如果模型的 AUC 比 0.5 还小，这样的模型可以求解器镜像，也就是将分类结果反转来获得优于随机猜测的结果。

## 总结

* 在二分类任务中，模型性能度量的基本指标是精度和错误率，两者和为 1；
* 混淆矩阵是个 2 X 2 的性能度量矩阵，器元素分别是真正例、假正例、假反例和真反例的数目；
* P-R 曲线表示的是查准率和查全率之间的关系，曲线在点(1,1)上达到最优性能；
* ROC曲线表示的是真正例率和假正例率之间的关系，曲线在点(0,1)上达到最优性能；