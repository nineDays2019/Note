# 机器学习 [06] 🔥的力量

*模型的验证方法* From <机器学习 40 讲>

模型本身及其背后学习方法的**泛化性能**，也就是模型对未知数据的预测能力，是机器学习的核心问题。

由于模型的泛化性能和它的复杂度是直接挂钩的，所以模型验证的任务就是确定模型的复杂度以避免过拟合的发生。

估计泛化性能时，最重要的依据就是模型在训练数据集上的**精度**。



## k 折交叉验证法 (k-fold cross validation)

k 折交叉验证将原始数据集随机划分为 k 个相同大小的子集，并进行 k 轮验证。每一轮验证都选择一个子集作为验证集，而将剩余的 k - 1 个子样本作为训练集。由于每一轮选择的验证集都互不相同，每一轮的验证结果也是不同的，k 个结果的均值就是对泛化性能的最终估计值。

k 折交叉验证中 k 值的选取直接决定估计结果的精确程度。较小的 k 值意味着更少的数据被用于训练模型，这将导致每一轮估计得到的结果更加集中，但都会偏离真正的泛化误差，也就是方差较小而偏差较大。随着 k 的不断增加，越来越多的数据被用在模型拟合上，计算出的泛化误差也越来越接近真实值。但由于训练数据的相似度越来越高，训练出来的模型也越来越像，这就导致在不用的验证集上产生较大的方差。


## 总结

* 模型验证的作用是选择最佳模型并确定其性能；
* 对数据的重采样可以直接实现对样本外误差，也就是泛化误差的估计；
* k 折交叉验证是无放回的重采样方法；
* 自助采样是有放回的重采样方法；

在机器学习中，参数和超参数是两个不同的概念。模型的参数是对模型的内部描述，超参数则是对模型的外部描述。模型的验证实际上就是通过调整模型的超参数来控制模型复杂度，从而找到一组预测能力最强的模型参数。